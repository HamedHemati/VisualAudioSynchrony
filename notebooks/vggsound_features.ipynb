{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/hhemati/.cache/torch/hub/harritaylor_torchvggish_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGGish(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (embeddings): Sequential(\n",
       "    (0): Linear(in_features=12288, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=4096, out_features=128, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (pproc): Postprocessor()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('harritaylor/torchvggish', 'vggish')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_path = \"/raid/hhemati/Datasets/MultiModal/VGGSound/wavs/video_12512.wav\"\n",
    "out = model.forward(wav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(128.7453, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.mean(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([175.,   8., 147.,  97., 215.,  76.,  77., 130., 148., 175., 151.,  51.,\n",
       "        120., 147., 101.,  35., 110., 238., 197., 194.,   0., 208.,  99., 178.,\n",
       "         70., 152., 150., 186., 124.,  68., 193., 131., 106.,  82., 140., 131.,\n",
       "        139., 121., 184., 136., 116., 175.,  32., 144., 123., 164., 133.,  92.,\n",
       "        124., 110., 127.,  94., 129.,  78.,  86., 151., 126., 106., 113., 206.,\n",
       "        131., 122., 121.,  97., 174., 168.,  82., 124., 144., 135., 146., 113.,\n",
       "        127., 188., 138., 155., 132., 138.,  94., 168., 100., 194., 153., 131.,\n",
       "         92., 102., 138., 202., 147.,  89.,  63., 145.,  96., 113., 111., 172.,\n",
       "         89.,  51., 122., 211., 207., 122., 120., 114., 106., 183.,  84., 115.,\n",
       "        171., 130., 179., 136.,  68., 137.,  72.,  56., 147., 184.,  49., 217.,\n",
       "        102., 116., 101.,  84., 171., 148.,  69., 255.],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum((out[0]-out[4])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([175. ,   8. , 147. ,  97. , 215. ,  76. ,  77. , 130. , 148. ,\n",
       "       175. , 151. ,  51. , 120. , 147. , 101. ,  35. , 110. , 238. ,\n",
       "       197. , 194. ,   0. , 208. ,  99. , 178. ,  69.8, 152.2, 150. ,\n",
       "       186. , 124. ,  68. , 193. , 131. , 106. ,  82. , 140. , 131. ,\n",
       "       139. , 121. , 184. , 136. , 116. , 175. ,  32. , 144. , 123. ,\n",
       "       164. , 133. ,  92. , 124. , 110.2, 127. ,  94. , 129. ,  78. ,\n",
       "        86. , 151. , 126. , 106. , 113. , 206. , 131. , 122. , 121. ,\n",
       "        97. , 174. , 168. ,  82. , 124. , 144. , 135. , 146. , 112.8,\n",
       "       127.2, 188. , 138. , 155. , 132. , 138. ,  94. , 168. , 100. ,\n",
       "       194. , 153. , 131. ,  92. , 102. , 138. , 202. , 147. ,  88.8,\n",
       "        63. , 145. ,  96. , 112.8, 111. , 172. ,  89. ,  51. , 122. ,\n",
       "       210.8, 207. , 122. , 120. , 114. , 106. , 183. ,  84. , 115. ,\n",
       "       171. , 130. , 179. , 136. ,  68. , 137. ,  72. ,  56. , 147. ,\n",
       "       184. ,  48.8, 217. , 102. , 116. , 101. ,  84. , 171. , 148. ,\n",
       "        69. , 255. ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(out, dim=0).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_path = \"/raid/hhemati/Datasets/MultiModal/VGGSound/wavs/video_1109.wav\"\n",
    "out1 = model.forward(wav_path)\n",
    "wav_path = \"/raid/hhemati/Datasets/MultiModal/VGGSound/wavs/video_146.wav\"\n",
    "out2 = model.forward(wav_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(296., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.sqrt((out1[-1] - out2[-1])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(78.7999, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.sqrt((torch.mean(out1, dim=0) - torch.mean(out2, dim=0))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
